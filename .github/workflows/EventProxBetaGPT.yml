name: EventProxPart (FlowAgility eventos + participantes)Beta

on:
  workflow_dispatch:
    inputs:
      limit_events:
        description: "Máximo de eventos a procesar (0 = sin límite)"
        required: false
        default: "35"
      max_runtime_min:
        description: "Corte ordenado a los N minutos (0 = sin límite)"
        required: false
        default: "25"
  schedule:
    # 03:40 UTC ≈ 05:40 Europe/Madrid (según DST)
    - cron: "40 3 * * *"

permissions:
  contents: read

concurrency:
  group: eventproxpart-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run-scrape:
    runs-on: ubuntu-24.04
    timeout-minutes: 90

    env:
      TZ: Europe/Madrid
      PYTHONUNBUFFERED: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"

      # ---- Scraper ENV ----
      HEADLESS: "true"
      INCOGNITO: "true"
      OUT_DIR: "./output"
      MAX_SCROLLS: "12"
      SCROLL_WAIT_S: "2.0"
      LIMIT_EVENTS: "${{ github.event.inputs.limit_events || '35' }}"
      MAX_RUNTIME_MIN: "${{ github.event.inputs.max_runtime_min || '25' }}"

      # Throttling + resume (para 02EventosProxParticipantesGitHubGPT.py)
      THROTTLE_EVENT_S: "3.0"
      THROTTLE_PAGE_MIN_S: "1.2"
      THROTTLE_PAGE_MAX_S: "2.5"
      THROTTLE_TOGGLE_MIN_S: "0.9"
      THROTTLE_TOGGLE_MAX_S: "2.2"
      AUTO_SAVE_EVERY: "10"
      RESUME: "true"
      RESUME_FILE: ""

      # Credenciales (usar Secrets)
      FLOW_EMAILRq: "${{ secrets.FLOW_EMAILRQ }}"
      FLOW_PASSRq: "${{ secrets.FLOW_PASSRQ }}"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: Install chromedriver
        uses: nanasess/setup-chromedriver@v2

      - name: Show Chrome versions
        run: |
          google-chrome --version || true
          google-chrome-stable --version || true
          chromedriver --version || true

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install selenium webdriver-manager beautifulsoup4 python-dotenv
          fi

      - name: Prepare output dir
        run: |
          mkdir -p "${OUT_DIR}"
          echo "OUT_DIR contents (before):"
          ls -la "${OUT_DIR}" || true

      - name: Run Python scraper (events + participants)
        timeout-minutes: 60
        env:
          HEADLESS: "${{ env.HEADLESS }}"
          INCOGNITO: "${{ env.INCOGNITO }}"
          OUT_DIR: "${{ env.OUT_DIR }}"
          MAX_SCROLLS: "${{ env.MAX_SCROLLS }}"
          SCROLL_WAIT_S: "${{ env.SCROLL_WAIT_S }}"
          LIMIT_EVENTS: "${{ env.LIMIT_EVENTS }}"
          MAX_RUNTIME_MIN: "${{ env.MAX_RUNTIME_MIN }}"
          THROTTLE_EVENT_S: "${{ env.THROTTLE_EVENT_S }}"
          THROTTLE_PAGE_MIN_S: "${{ env.THROTTLE_PAGE_MIN_S }}"
          THROTTLE_PAGE_MAX_S: "${{ env.THROTTLE_PAGE_MAX_S }}"
          THROTTLE_TOGGLE_MIN_S: "${{ env.THROTTLE_TOGGLE_MIN_S }}"
          THROTTLE_TOGGLE_MAX_S: "${{ env.THROTTLE_TOGGLE_MAX_S }}"
          AUTO_SAVE_EVERY: "${{ env.AUTO_SAVE_EVERY }}"
          RESUME: "${{ env.RESUME }}"
          RESUME_FILE: "${{ env.RESUME_FILE }}"
          FLOW_EMAILRq: "${{ env.FLOW_EMAILRq }}"
          FLOW_PASSRq: "${{ env.FLOW_PASSRq }}"
        run: |
          echo "=== EJECUTANDO SCRAPER ==="
          python ./02EventosProxParticipantesGitHubGPT.py --module all
          echo "=== SCRAPER COMPLETADO ==="

      # ======= BLOQUE EXACTO QUE PEDISTE (verificación/compresión/FTP) =======

      - name: Verify generated files
        run: |
          echo '=== VERIFICANDO ARCHIVOS GENERADOS ==='
          ls -la ./output/
          
          # Verificar que existen los archivos finales
          missing_files=0
          required_files=("01events.json" "02info.json")
          
          for file in "${required_files[@]}"; do
              if [ -f "./output/$file" ]; then
                  file_size=$(stat -c%s "./output/$file")
                  echo "✅ $file: ENCONTRADO (${file_size} bytes)"
              else
                  echo "❌ $file: NO ENCONTRADO"
                  missing_files=$((missing_files + 1))
              fi
          done
          
          if [ $missing_files -eq 0 ]; then
              echo "✅ TODOS los archivos requeridos están presentes"
          else
              echo "❌ Faltan $missing_files archivos requeridos"
              exit 1
          fi

      - name: Compress JSON files for FTP
        run: |
          echo "=== COMPRIMIENDO ARCHIVOS PARA FTP ==="
          
          # Comprimir archivos JSON con gzip (máxima compresión)
          for file in ./output/0*.json; do
              if [ -f "$file" ]; then
                  echo "Comprimiendo: $(basename $file)"
                  gzip -9 -c "$file" > "${file}.gz"
                  original_size=$(stat -c%s "$file")
                  compressed_size=$(stat -c%s "${file}.gz")
                  compression_ratio=$(( (compressed_size * 100) / original_size ))
                  echo "  ${original_size} bytes → ${compressed_size} bytes (${compression_ratio}%)"
              fi
          done
          
          echo "=== ARCHIVOS COMPRIMIDOS ==="
          ls -la ./output/*.gz

      - name: Upload compressed files to FTP
        env:
          FTP_SERVER: ${{ secrets.FTP_SERVER }}
          FTP_USERNAME: ${{ secrets.FTP_USERNAME }}
          FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
          FTP_REMOTE_DIR: ${{ secrets.FTP_REMOTE_DIR }}
        run: |
          echo '=== SUBIENDO ARCHIVOS COMPRIMIDOS ==='
          
          # Verificar que las variables estén configuradas
          if [ -z "$FTP_SERVER" ] || [ -z "$FTP_USERNAME" ] || [ -z "$FTP_PASSWORD" ]; then
              echo "❌ ERROR: Variables FTP no configuradas correctamente"
              exit 1
          fi
          
          REMOTE_DIR="${FTP_REMOTE_DIR}/Competiciones/EventosProx/Flow/data"
          BASE_URL="ftp://${FTP_SERVER}${REMOTE_DIR}"
          
          echo "Subiendo a: ${BASE_URL}/"
          
          # Archivos comprimidos a subir
          COMPRESSED_FILES=("01events.json.gz" "participantes_detallados.json.gz")
          
          # Subir archivos comprimidos
          for file in "${COMPRESSED_FILES[@]}"; do
              local_file="./output/$file"
              
              if [ ! -f "$local_file" ]; then
                  echo "❌ Archivo comprimido $file no encontrado"
                  continue
              fi
              
              echo "📤 Subiendo archivo comprimido: $file"
              
              # Subir archivo comprimido
              curl --fail \
                   --ssl-reqd \
                   --ftp-create-dirs \
                   --disable-epsv \
                   --ftp-skip-pasv-ip \
                   --user "${FTP_USERNAME}:${FTP_PASSWORD}" \
                   --upload-file "$local_file" \
                   "${BASE_URL}/$file"
              
              if [ $? -eq 0 ]; then
                  echo "✅ $file subido exitosamente"
              else
                  echo "❌ Error subiendo archivo comprimido $file"
                  
                  # Intentar subir el archivo original sin comprimir
                  original_file=${file%.gz}
                  echo "🔄 Intentando subir archivo original: $original_file"
                  
                  curl --fail \
                       --ssl-reqd \
                       --user "${FTP_USERNAME}:${FTP_PASSWORD}" \
                       --upload-file "./output/$original_file" \
                       "${BASE_URL}/$original_file" && \
                  echo "✅ $original_file subido exitosamente" || \
                  echo "❌ Error subiendo $original_file también"
              fi
              
              sleep 1
          done
          
          # También intentar subir el 01events.json sin comprimir (siempre es pequeño)
          echo "📤 Subiendo 01events.json (sin comprimir)"
          curl --fail \
               --ssl-reqd \
               --user "${FTP_USERNAME}:${FTP_PASSWORD}" \
               --upload-file "./output/01events.json" \
               "${BASE_URL}/01events.json" && \
          echo "✅ 01events.json subido exitosamente" || \
          echo "⚠️  No se pudo subir 01events.json sin comprimir"

      - name: Create backup directory
        run: mkdir -p ./backup

      - name: Backup uncompressed files
        run: |
          echo "=== CREANDO BACKUP LOCAL ==="
          cp ./output/01events.json ./backup/
          cp ./output/participantes_detallados.json ./backup/ || true
          echo "Backup de archivos sin comprimir creado en ./backup/"

      - name: Upload backup as artifact
        uses: actions/upload-artifact@v4
        with:
          name: json-backup-uncompressed
          path: |
            ./backup/01events.json
            ./backup/participantes_detallados.json
          retention-days: 7

      - name: Upload compressed files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: json-compressed
          path: |
            ./output/01events.json.gz
            ./output/02info.json.gz
          retention-days: 3

      - name: Debug on failure
        if: failure()
        run: |
          echo "=== DEBUGGING FAILURE ==="
          echo "Listando archivos en output:"
          ls -la ./output/ 2>/dev/null || echo "No output directory"
          echo "Listando archivos en backup:"
          ls -la ./backup/ 2>/dev/null || echo "No backup directory"
          echo "=== VERIFICANDO CHROME ==="
          which google-chrome-stable && echo "Chrome encontrado: $(google-chrome-stable --version)" || echo "Chrome NO encontrado"
          which chromedriver && echo "Chromedriver encontrado: $(chromedriver --version)" || echo "Chromedriver NO encontrado"
          echo "=== TAMAÑOS DE ARCHIVOS ==="
          for file in ./output/*.json ./output/*.gz; do
              if [ -f "$file" ]; then
                  size=$(stat -c%s "$file")
                  echo "$(basename $file): $size bytes"
              fi
          done
